{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_recall_curve, auc, ndcg_score\n",
    "from tdescore.classifier.train import train_classifier\n",
    "from tdescore.classifier.features import relevant_columns, column_descriptions\n",
    "from tdescore.classifier.collate import get_classified_sources, convert_to_train_dataset\n",
    "import matplotlib.patheffects as path_effects\n",
    "import pandas as pd\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a370bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"tdescore\").setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c130fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "\n",
    "all_all_res, clfs = train_classifier(\n",
    "    n_iter=n_iter,\n",
    "    columns=relevant_columns\n",
    ")\n",
    "\n",
    "n_estimator_set = list(sorted(clfs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18684245",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle(\"tdescore\")\n",
    "c_metrics = [x for x in all_all_res.columns if x not in [\"n_estimator\", \"all_res\"]]\n",
    "for i, y in enumerate(c_metrics):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.plot(all_all_res[\"n_estimator\"], all_all_res[y]*100., color=f\"C{i}\")\n",
    "    plt.scatter(n_estimator_set, all_all_res[y]*100., color=f\"C{i}\")\n",
    "    plt.ylabel(f'{y} [%]')\n",
    "\n",
    "plt.subplots_adjust(wspace=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"precision_recall_area\"\n",
    "\n",
    "best_index = all_all_res[metric].idxmax()\n",
    "\n",
    "best_estimator = all_all_res.iloc[best_index][\"n_estimator\"]\n",
    "\n",
    "print(f\"Best value is {best_estimator}\")\n",
    "\n",
    "clf = clfs[best_estimator]\n",
    "all_res = all_all_res[all_all_res[\"n_estimator\"] == best_estimator][\"all_res\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4edc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten():\n",
    "    true_class = []\n",
    "    all_probs = []\n",
    "    for i in range(n_iter):\n",
    "        probs = all_res[f\"probs_{i}\"]\n",
    "        true_class += all_res[f\"class\"].tolist()\n",
    "        all_probs += probs.tolist()\n",
    "    return true_class, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c310fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tclass, aprobs = flatten()\n",
    "\n",
    "fscale = 4.\n",
    "figsize=(fscale*1.618, fscale)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(tclass, aprobs)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc_score(tclass, aprobs):.3f}\")\n",
    "plt.plot([0.0, 1.0], [0.0, 1.0], linestyle=\":\", label=\"random AUC=0.500\")\n",
    "plt.xlabel(\"false positive\")\n",
    "plt.ylabel(\"true positive\")\n",
    "plt.legend()\n",
    "plt.xlim(0.0, 0.15)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.savefig(\"figures/roc.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fpr, fnr, thresholds = metrics.det_curve(tclass, aprobs)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(fpr, fnr)\n",
    "plt.xlabel(\"false positive\")\n",
    "plt.ylabel(\"false negative\")\n",
    "plt.xlim(0.0, 0.1)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.savefig(\"figures/fp_fn.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "x, y, thresholds = metrics.precision_recall_curve(tclass, aprobs)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.savefig(\"figures/precision_recall.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr, recall, thresholds = metrics.precision_recall_curve(tclass, aprobs)\n",
    "\n",
    "index = np.arange(len(thresholds))\n",
    "\n",
    "mask = recall[1:] >= 0.95\n",
    "\n",
    "loose_index = max(index[mask])\n",
    "\n",
    "threshold_loose = thresholds[loose_index]\n",
    "print(f\"Loose threshold {threshold_loose:.2f}, Precision={100.*pr[loose_index]:.1f}%, Recall={100.*recall[loose_index]:.1f}%\")\n",
    "\n",
    "\n",
    "mask = pr[:-1] >= 0.95\n",
    "strict_index = min(index[mask])\n",
    "\n",
    "threshold_strict = thresholds[strict_index]\n",
    "print(f\"Strict Threshold {threshold_strict:.2f}, Precision={100.*pr[strict_index]:.1f}%, Recall={100.*recall[strict_index]:.1f}%\")\n",
    "\n",
    "mask = pr[:-1] >= 0.8\n",
    "\n",
    "balanced_index = min(index[mask])\n",
    "\n",
    "threshold_balanced = thresholds[balanced_index]\n",
    "print(f\"Balanced Threshold {threshold_balanced:.2f}, Precision={100.*pr[balanced_index]:.1f}%, Recall={100.*recall[balanced_index]:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fd846",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=figsize)\n",
    "plt.plot(thresholds[:-1], x[1:-1], label=\"Precision\")\n",
    "plt.plot(thresholds[:-1], y[1:-1], label=\"Recall\")\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.xlabel(r\"$\\it{tdescore}$ threshold\")\n",
    "plt.legend()\n",
    "for cut in [threshold_loose, threshold_balanced, threshold_strict]:\n",
    "    plt.axvline(cut, linestyle=\":\", color=\"k\")\n",
    "plt.savefig(\"figures/precision_recall.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e951bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(cut, label):\n",
    "    print(f\"Cut of {cut:.3f}\")\n",
    "\n",
    "    base_cm = confusion_matrix(tclass, np.array(aprobs) > cut)\n",
    "\n",
    "    for k in range(2):\n",
    "        \n",
    "        plt.figure()\n",
    "        \n",
    "        if k==0:\n",
    "            cm = base_cm/np.sum(base_cm, axis=0)\n",
    "        elif k==1:\n",
    "            cm = (base_cm.T/np.sum(base_cm, axis=1)).T\n",
    "        else:\n",
    "            cm = base_cm\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        ax.imshow(cm, cmap=plt.cm.Blues)\n",
    "        ax.set_title(f'{[\"Prediction-Normalised\", \"Truth-Normalised\", \"\"][k]} Confusion Matrix ({label})')\n",
    "        ax.set_xticks(np.arange(len(cm)))\n",
    "        ax.set_yticks(np.arange(len(cm)))\n",
    "        ax.set_xticklabels(['Non-TDE', \"TDE\"])\n",
    "        ax.set_yticklabels(['Non-TDE', \"TDE\"])\n",
    "        ax.set_xlabel('Predicted label')\n",
    "        ax.set_ylabel('True label')\n",
    "        for i in range(len(cm)):\n",
    "            for j in range(len(cm)):\n",
    "                ax.text(j, i, f\"{100.*cm[i, j]:.1f}%\\n\\n({base_cm[i, j]})\", ha='center', va='center', color='white', fontsize=15,\n",
    "                        path_effects=[path_effects.Stroke(linewidth=2, foreground='black'), path_effects.Normal()]\n",
    "                       )        \n",
    "        path = f\"figures/matrix_{label}_{k}.pdf\"\n",
    "        plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cut in enumerate([threshold_loose, threshold_balanced, threshold_strict]):\n",
    "    plot_matrix(cut, label=[\"Inclusive\", \"Balanced\", \"Clean\"][i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0cb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame([relevant_columns, column_descriptions, list(clf.feature_importances_), ]).T\n",
    "features.sort_values(by=2, ascending=False, inplace=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feature = len(relevant_columns)\n",
    "\n",
    "text_str = r\"\"\"\\begin{table*}[]\n",
    "\\centering\n",
    "    \\begin{tabular}{c|c|c}\n",
    "    \\textbf{Feature} &\\textbf{Description}& \\textbf{Importance (\\%)}\\\\\n",
    "    \\hline\n",
    "\"\"\"\n",
    "print(text_str)\n",
    "for _, row in features.iterrows():\n",
    "    name = row[0].replace('_', '\\_')\n",
    "    print(f\"\\t{name} & {row[1]} & {100.*row[2]:.1f} \\\\\\\\\")\n",
    "print(r\"\\end{tabular}\")\n",
    "print(r\"\\caption{Relative importance of all \" + str(len(features)) + r\" features in \\tdes, calculated by \\xgboost \\citep{xgboost} using the standard averaging of importance across all decision trees in the final model \\citep[see e.g][]{ml_textbook}.}\")\n",
    "print(r\"\"\"\\label{tab:importance}\n",
    "\\end{table*}\"\"\")\n",
    "# print(r\"\"\"\\end{tabular}\n",
    "# \\caption{Relative importance of all\"\"\" + len(features) + \"\"\"features in \\tdes, calculated by \\xgboost \\citep{xgboost} using the standard averaging of importance across all decision trees in the final model \\citep[see e.g][]{ml_textbook}.}\n",
    "# \\label{tab:importance}\n",
    "# \\end{table*}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49284c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_sources = get_classified_sources()\n",
    "data_to_use = convert_to_train_dataset(classified_sources)\n",
    "\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(data_to_use)\n",
    "expected_value = explainer.expected_value\n",
    "\n",
    "explainer = shap.Explainer(clf, data_to_use, feature_names=relevant_columns)\n",
    "shap_values = explainer(data_to_use)\n",
    "\n",
    "def explain(name, classification=None):\n",
    "    fig = plt.figure()\n",
    "    index = classified_sources[\"ztf_name\"].tolist().index(name)\n",
    "\n",
    "    shap.plots.waterfall(\n",
    "        shap_values[index],\n",
    "        max_display=5, show=False\n",
    "    )\n",
    "    \n",
    "    if classification is not None:\n",
    "        title = f\"{name} ({classification})\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = explain(\"ZTF19aapreis\", \"Tidal Disruption Event\")\n",
    "fig.savefig(\"figures/ZTF19aapreis.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6704c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdescore_env",
   "language": "python",
   "name": "tdescore_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
